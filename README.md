# Cybernetics Done Right: The Big Picture

> The idea behind **Cybernetics** curriculum is great: an **interdisciplinary** approach to solving complex economic problems. Unfortunately, the execution lacks behind and is not in line with the grand vision or recent developments. This repository will walk through 5 years with an **alternative curricula**, code and learning paths, which is:

* Theoretically rigorous and sound, leverages mathematical, statistical and domain understanding. Some elements of abstract math to understand the underlying foundations.
* Applications are based on actual code and implementations, on real data. Introduces real world challenges related to deploying models and improving decision making in organizations.
* Simulations are used extensively to get a feel of the behavior of models and algorithms.


Keeping these aspects in mind, after a careful analysis of topics, fields and their connections, I identified different (inter)dependent tracks one can follow:

1. **Data science:** starting with basic statistics and ending up with Advanced Econometrics, Bayesian analysis, Data Mining, Machine and Deep Learning.
2. **Business Economics** completes the first with the necessary context on problems, theory, challenges, and methodologies in order to bring value to organizations through problem solving.
3. **Quantitative Economics: Neoclassical and Heterodox** is a more research-oriented topic, focused on current challenges the profession of economics is facing.
4. **Economic Complexity and Complex Adaptive Systems** can provide a powerful set of tools (System Dynamics, Network Theory, Cybernetics, General Systems' Theory, etc) in any field, but is especially relevant in management and economics.

It is hard to teach these topics in a way which is both theoretically sound and can be immediately applied. After recognizing that there is no silver bullet or free lunch, my conclusion is that following the principles above consistently, dramatically increases the chances of preparing a new generation ready to tackle the messy, ill-defined problems they will encounter.

I often find myself truly understanding something, only after I code it up and understand the mathematics (of a model) well, then try to think of how would I apply this in practice in different contexts. This hints to the idea that we need some complementary background and tools, some of them right from the beginning:

1. **Computer science.** Even though I had two semesters of C/C++, I never wrote a line of C in production. The benefit of teaching computer science with C is evident, but the price for that is time. My vision is that for an applied researcher / data scientist, it is of foremost importance to start working with data as soon as possible. Let me give a few examples:
    * In a statistics/econometrics class, R makes a world of difference, giving the student in the span of a semester, skills which can be applied everywhere.
    * An operations research lab benefits immensely by being able to code a Linear Programming / Dijksta / Simplex in Python, or use an existing package to solve a real problem.
    * In an introductory finance class, using Python would enable students not only to understand what their future finance colleagues are doing, but do automate a lot of work.
    * In an economics class, pulling some open data would enable them to critically think about a claim/theory mentioned in a course. It forces the student to ask the question: "How would I go about to test this hypothesis empirically?".
2. **Operations research and scientific computing.** There are a lot of problems we have no hope to find an optimal solution in a reasonable amount of time. This is why we're searching for good solutions with numerical methods, simulations and heuristics. A good knowledge of optimization methods and MCMC is invaluable for an applied statistician or machine learning engineer.
3. **Applied mathematics:** Almost all the topics mentioned above can be treated from a more mathematical, theoretical perspective. I find a lot of value even in more abstract treatments, so how do we get over the "I would never use this in real life"? By making it relatable! Let me give a few examples of successful courses doing it:
    * Calculus Applied!, Coding the Matrix
    * Yaser Abu-Mostafa's Learning From Data
    * Computational methods for Data Analysis
    * Univesity of Kyoto's Stochastic Processes course


### **Why am I doing this?**
During the last five years, I accumulated tens of thousands of pages of handwritten notes from university and numerous online couses, but I have this nagging feeling that only a tiny amount of it was put to good use. The code snippets I wrote are also scattered all over the place, earlier ones being of questionable quality.

At this moment I can look at it with a fresh perspective, skills acquired in the industry, and sitting on the shoulders of these field's giants. Reading the original papers and implementing models from scratch has been my passion for a few years.

I am confident that an excellent way of deeply understanding the fundamentals is to explain them. From there, I can deal with any new problem with a much greater deal of confidence and effectiveness.


<!--
## Computer Science

A focus shifted from software development to **scientific computing**, emphasizing the challenges in deploying models, BI, data modeling, big data, streaming, containers and automation. Usage of high-level languages such as Python and R, containters, APIs instead of low-level concerns of pointers, memory allocation and parallel computing.


## Mathematics
A rigorous preparation and mathematical background.

## Statistics and Econometrics
A path towards Computer Age Statistical Inference.


## Machine Learning and Deep Learning

A path to the cutting-edge methods and models for machine learning.

> Deep Learning specialization by **deeplearning.AI**:

1. [Coursera, Andrew Ng](https://www.coursera.org/learn/neural-networks-deep-learning): Neural Networks and Deep learning:
2. [Coursera, Andrew Ng](https://www.coursera.org/learn/machine-learning-projects): Structuring Machine learning projects
3. [Coursera, Andrew Ng](https://www.coursera.org/learn/deep-neural-network): Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization
4. [Coursera, Andrew Ng](https://www.coursera.org/learn/convolutional-neural-networks): Convolutional Neural Networks
5. [Coursera, Andrew Ng](https://www.coursera.org/learn/nlp-sequence-models): Sequence Models


> Deep Learning in Tensorflow by **deeplearning.AI**

1. [Coursera, Deeplearning.AI](https://www.coursera.org/learn/natural-language-processing-tensorflow) Natural Language processing in Tensorflow
2. [Coursera, Deeplearning.AI](https://www.coursera.org/learn/convolutional-neural-networks-tensorflow) Convolutional Neural Networks in Tensorflow
3. [Coursera, Deeplearning.AI](https://www.coursera.org/learn/tensorflow-sequences-time-series-and-prediction) Sequences, Time Series and Predictions in Tensorflow

> Practical and Miscellaneous

1. [Coursera, IBM](https://www.coursera.org/learn/machine-learning-with-python/home/welcome) Machine Learning with Python


## Economics and Business

A pluralist perspective over economic questions and an overview of  **modern** management challenges and methodologies.
-->
